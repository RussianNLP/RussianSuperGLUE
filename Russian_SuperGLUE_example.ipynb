{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uu9C3-LgY-zx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy\n",
    "import os\n",
    "###!!! Attention!!! Для корректной работы jiant необходима версия allennlp===0.9.0\n",
    "### и версия трансформеров transformers==2.11.0\n",
    "### с более поздними версиями могут возникнуть проблемы в совместимости\n",
    "!pip install transformers allennlp===0.9.0\n",
    "!pip install transformers==2.11.0\n",
    "#!pip install jsondiff\n",
    "#!pip install pyhocon\n",
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WtjPCJAckV8"
   },
   "source": [
    "**Пример запуска baseline модели для Russian-SUPERGlue**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81SBfVUmZB7u"
   },
   "outputs": [],
   "source": [
    "#!unzip jiant-russian.zip\n",
    "os.chdir('./jiant-russian/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DP1fs9zdfaij"
   },
   "source": [
    "**Настройка config'а**\n",
    "\n",
    "\n",
    "Для работы pipelin'а необходимо указать путь к данным и путь для сохранения модели в  `user_config.sh`:\n",
    "\n",
    "1) `export JIANT_DATA_DIR=./combined/` - путь к данным для тасков. По умолчанию указана папка `combined`, которую необходимо поместить в корневую директорию.\n",
    "\n",
    "2) `export JIANT_PROJECT_PREFIX=./model_dir/` - путь, где сохраняются модели, логи, результаты предсказания. По умолчанию указана `./model_dir/`.\n",
    "\n",
    "Параметры, специфичные для модели и параметры обучения указываются в конфиге модели: `jiant/config/superglue_bert.conf`. \n",
    "\n",
    "\n",
    "Например, там задается:\n",
    "\n",
    " `input_module` - используемая [hugging face](https://huggingface.co/models) модель (по умолчанию `\"DeepPavlov/rubert-base-cased-conversational\"`). На текущий момент поддерживаются следующие модели:\n",
    " ```\n",
    " DeepPavlov/rubert-base-cased\n",
    " DeepPavlov/rubert-base-cased-conversational\n",
    " DeepPavlov/rubert-base-cased-sentence\n",
    " bert-base-multilingual-cased\n",
    " bert-base-multilingual-uncased \n",
    " sberbank-ai/rugpt3large_based_on_gpt2\n",
    " sberbank-ai/rugpt3medium_based_on_gpt2\n",
    " sberbank-ai/rugpt3small_based_on_gpt2\n",
    " sberbank-ai/rugpt2large\n",
    " ```\n",
    " и другие модели, имплементированные в оригинальной библиотеке [jiant](https://github.com/nyu-mll/jiant).\n",
    "\n",
    "\n",
    " `exp_name` - короткое название эксперимента, по умолчанию `rubert`\n",
    " \n",
    " **Attention** Если вы перезапускаете экперимент для конкретного таска, например, с другими параметрами или после неудачного запуска, лучше изменить название `exp_name`, дабы избежать нежелательной подгрузки из кэша.\n",
    "\n",
    " `max_val, max_epochs, learning_rate` и другие.\n",
    "\n",
    "**Замечание** Для gpt моделей, возможно, также стоит добавить дополнительные параметры, накие как: \n",
    "\n",
    "`max_grad_norm = 1`\n",
    "`grad_clipping = 1`\n",
    "\n",
    "\n",
    "\n",
    "**Данные** \n",
    "\n",
    "Данные можно скачать с сайта [RussianGLUE](https://russiansuperglue.com/tasks/). По [ссылке](https://russiansuperglue.com/tasks/download) можно скачать данные для всех таксков разом. Дальше достаточно будет разархивировать архив и указать путь к нему в качестве `export JIANT_PROJECT_PREFIX=` в конфиге.\n",
    "\n",
    "**Структура данных**\n",
    "\n",
    "Данные для каждого из заданий должны лежать в подпапке с аналогичным названием в `export JIANT_PROJECT_PREFIX=` (в [общем архиве с данными](https://russiansuperglue.com/tasks/download) как раз такая струтура): \n",
    "\n",
    "1) DaNetQa\n",
    "\n",
    "2) LiDiRus\n",
    "\n",
    "3) MuSeRC\n",
    "\n",
    "4) PARus\n",
    "\n",
    "5) RCB\n",
    "\n",
    "6) RuCoS\n",
    "\n",
    "7) RUSSE\n",
    "\n",
    "8) RWSD\n",
    "\n",
    "9) TERRa\n",
    "\n",
    "Для запуска всех тасков кроме диагностического LiDiRus в папке должны находиться `train.jsonl, val.jsonl, test.jsonl`. Для LiDiRus в соответствующую папку надо положить `LiDiRus.jsonl`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l0vzVwEdDN7d"
   },
   "source": [
    "**Запуск baseline**\n",
    "\n",
    "Запуска baselin'ов осуществляется с помощью скрипта `./scripts/russian-superglue-baselines.sh`. Для обучения модели и получения предсказаний необходимо запустить скрипт с указанием необходимого таска (предсказания для диагностического `LiDiRus` вычисляются при обучении на TERRa, то есть при запуске terra модель делает предсказания как для terra_test, так и для lidirus.\n",
    "\n",
    "\n",
    "**Usage:**\n",
    "```\n",
    "   ./scripts/superglue-baselines.sh ${TASK} ${GPU_ID} ${SEED}\n",
    "   - TASK: one of {\"danetqa\", \"rcb\", \"parus\", \"muserc\", \"rucos\", \"terra\", \"russe\", \"rwsd\", \"all\"},\n",
    "\n",
    "   - GPU_ID: GPU to use, or -1 for CPU. Defaults to 0.\n",
    "   - SEED: random seed. Defaults to 111.\n",
    "```\n",
    "\n",
    "Для запуска всех тасков необходимо выбрать опцию `all.` При этом таски запускаются в следующем порядке (`LidiRus` вызывается внутри `TERRa`):     \n",
    "```    \n",
    "    rwsd\n",
    "    russe\n",
    "    terra\n",
    "    rucos\n",
    "    muserc\n",
    "    parus\n",
    "    rcb\n",
    "    danetqa\n",
    "```\n",
    "\n",
    "Ниже приведен пример базового запуска для задания `TERRa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVwaqEzyZMTO"
   },
   "outputs": [],
   "source": [
    "!chmod 755 ./scripts/russian-superglue-baselines.sh \n",
    "! ./scripts/russian-superglue-baselines.sh \"terra\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRHu4aNSFrSy"
   },
   "source": [
    "**Results**\n",
    "\n",
    "Результаты сохраняются в `model_dir/exp_name/task_name`. \n",
    "\n",
    "Скоры модели на валидации по всем отработанным таскам записываются в `model_dir/exp_name/results.tsv`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Ep3uiYoIEUO9",
    "outputId": "0093ecc1-5a28-487e-c9e0-22659417282a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terra\tmicro_avg: 0.658, macro_avg: 0.658, terra_accuracy: 0.658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TERRa results\n",
    "print(open('./model_dir/rubert/results.tsv').readlines()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "fEaFbsarEYm0",
    "outputId": "abbe97cd-4296-4781-b337-3b0070c927f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terra\tmicro_avg: 0.000, macro_avg: 0.000, lidirus_lex_sem: -0.067, lidirus_lex_sem__Redundancy: 0.060, lidirus_lex_sem__Symmetry/Collectivity: 0.175, lidirus_lex_sem__Named entities: -0.169, lidirus_lex_sem__Lexical entailment;Quantifiers: 0.000, lidirus_lex_sem__Lexical entailment: -0.030, lidirus_lex_sem__Quantifiers: -0.219, lidirus_lex_sem__Lexical entailment;Factivity: 0.000, lidirus_lex_sem__Factivity;Quantifiers: 0.000, lidirus_lex_sem__Factivity: 0.043, lidirus_pr_ar_str: -0.152, lidirus_pr_ar_str__Intersectivity;Ellipsis/Implicits: 0.000, lidirus_pr_ar_str__Coordination scope;Prepositional phrases: 0.000, lidirus_pr_ar_str__Coordination scope: 0.000, lidirus_pr_ar_str__Active/Passive;Prepositional phrases: 0.000, lidirus_pr_ar_str__Core args: 0.065, lidirus_pr_ar_str__Active/Passive: -0.333, lidirus_pr_ar_str__Restrictivity;Anaphora/Coreference: 0.000, lidirus_pr_ar_str__Genitives/Partitives: 0.000, lidirus_pr_ar_str__Relative clauses;Restrictivity: 0.000, lidirus_pr_ar_str__Anaphora/Coreference;Prepositional phrases: 0.000, lidirus_pr_ar_str__Ellipsis/Implicits;Anaphora/Coreference: 0.000, lidirus_pr_ar_str__Relative clauses: 0.000, lidirus_pr_ar_str__Restrictivity;Relative clauses: 0.000, lidirus_pr_ar_str__Nominalization: 0.000, lidirus_pr_ar_str__Datives: -0.509, lidirus_pr_ar_str__Ellipsis/Implicits: 0.000, lidirus_pr_ar_str__Core args;Anaphora/Coreference: -0.333, lidirus_pr_ar_str__Relative clauses;Anaphora/Coreference: 0.000, lidirus_pr_ar_str__Anaphora/Coreference: -0.218, lidirus_pr_ar_str__Nominalization;Genitives/Partitives: 0.000, lidirus_pr_ar_str__Restrictivity: 0.000, lidirus_pr_ar_str__Intersectivity: -0.054, lidirus_logic: -0.100, lidirus_logic__Conjunction;Negation: 0.000, lidirus_logic__Universal;Conjunction: 0.000, lidirus_logic__Non-monotone: 0.000, lidirus_logic__Disjunction;Conjunction: 0.000, lidirus_logic__Negation;Conditionals: 0.000, lidirus_logic__Negation: -0.077, lidirus_logic__Intervals/Numbers: 0.169, lidirus_logic__Double negation: -0.469, lidirus_logic__Downward monotone;Existential;Negation: 0.000, lidirus_logic__Disjunction;Non-monotone: 0.000, lidirus_logic__Intervals/Numbers;Non-monotone: 0.000, lidirus_logic__Downward monotone;Conditionals: 0.000, lidirus_logic__Temporal;Intervals/Numbers: 0.000, lidirus_logic__Disjunction;Conditionals;Negation: -1.000, lidirus_logic__Temporal: 0.061, lidirus_logic__Temporal;Conjunction: 0.000, lidirus_logic__Conditionals: 0.000, lidirus_logic__Double negation;Negation: 0.000, lidirus_logic__Disjunction;Negation: -0.200, lidirus_logic__Universal: -0.389, lidirus_logic__Downward monotone: 0.045, lidirus_logic__Existential;Negation: 0.000, lidirus_logic__Existential: -0.207, lidirus_logic__Universal;Negation: 0.000, lidirus_logic__Upward monotone: -0.067, lidirus_logic__Conjunction: 0.000, lidirus_logic__Existential;Upward monotone: 0.000, lidirus_logic__Disjunction: 0.262, lidirus_knowledge: -0.065, lidirus_knowledge__Common sense: -0.106, lidirus_all_mcc: -0.101, lidirus_accuracy: 0.545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LiDiRus results\n",
    "print(open('./model_dir/rubert/results.tsv').readlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8KYjfbq5FbnR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Russian SuperGLUE example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
